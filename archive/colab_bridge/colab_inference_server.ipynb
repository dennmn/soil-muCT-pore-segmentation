{"cells":[{"cell_type":"markdown","metadata":{"id":"g9etB6cc_xZU"},"source":["# SAM Inference Server (FastAPI + ngrok)\n","\n","This notebook mounts Google Drive, loads a SAM checkpoint, verifies CUDA, and starts a FastAPI inference server exposed via ngrok.\n"],"id":"g9etB6cc_xZU"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YdX59oRm_xZW","executionInfo":{"status":"ok","timestamp":1769939950118,"user_tz":-120,"elapsed":21405,"user":{"displayName":"רוני ש","userId":"03957075222652512697"}},"outputId":"2fedff29-b760-4670-8400-eac74e960353"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# 1) Mount Google Drive\n","from google.colab import drive\n","\n","drive.mount('/content/drive')\n"],"id":"YdX59oRm_xZW"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cSd0xzoT_xZY","executionInfo":{"status":"ok","timestamp":1769939950142,"user_tz":-120,"elapsed":13,"user":{"displayName":"רוני ש","userId":"03957075222652512697"}},"outputId":"25d0b3a5-6fc9-4f80-9eba-b3ee8db396dd"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Checkpoint path: /content/drive/MyDrive/soil_microCT_images/drive_scripts/napari_loader/checkpoints/sam_vit_h_4b8939.pth\n"]}],"source":["# 2) Configure checkpoint path (set DRIVE_SUBPATH env var if needed)\n","import os\n","\n","DRIVE_SUBPATH = 'soil_microCT_images/drive_scripts/napari_loader/checkpoints'\n","checkpoint_path = f\"/content/drive/MyDrive/{DRIVE_SUBPATH}/sam_vit_h_4b8939.pth\"\n","print(\"Checkpoint path:\", checkpoint_path)\n"],"id":"cSd0xzoT_xZY"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xLvayyWA_xZY","executionInfo":{"status":"ok","timestamp":1769939958928,"user_tz":-120,"elapsed":8783,"user":{"displayName":"רוני ש","userId":"03957075222652512697"}},"outputId":"47268dee-ceff-4659-980a-300b008f6b0b"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for segment_anything (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["# 3) Install dependencies\n","!pip -q install fastapi uvicorn pyngrok git+https://github.com/facebookresearch/segment-anything.git\n"],"id":"xLvayyWA_xZY"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zboapnwk_xZZ","executionInfo":{"status":"ok","timestamp":1769939962719,"user_tz":-120,"elapsed":3774,"user":{"displayName":"רוני ש","userId":"03957075222652512697"}},"outputId":"abb7b39e-094e-4f02-e7ef-ba1113a6460a"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["CUDA is available.\n"]}],"source":["# 4) Verify CUDA availability\n","import torch\n","\n","assert torch.cuda.is_available() is True, \"CUDA is not available. Please switch to a GPU runtime.\"\n","print(\"CUDA is available.\")\n"],"id":"zboapnwk_xZZ"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"osqcmrf5_xZZ","executionInfo":{"status":"ok","timestamp":1769940035945,"user_tz":-120,"elapsed":73221,"user":{"displayName":"רוני ש","userId":"03957075222652512697"}},"outputId":"0477e9e6-de0e-43ff-b153-56a575f6776f"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["SAM model loaded.\n"]}],"source":["# 5) Load SAM model\n","import os\n","import numpy as np\n","from PIL import Image\n","from segment_anything import sam_model_registry, SamPredictor\n","\n","if not os.path.isfile(checkpoint_path):\n","    raise FileNotFoundError(f\"Checkpoint not found: {checkpoint_path}\")\n","\n","sam = sam_model_registry[\"vit_h\"](checkpoint=checkpoint_path)\n","sam.to(device=\"cuda\")\n","predictor = SamPredictor(sam)\n","print(\"SAM model loaded.\")\n"],"id":"osqcmrf5_xZZ"},{"cell_type":"code","metadata":{"id":"JRMETcm-_xZZ","executionInfo":{"status":"ok","timestamp":1769940036547,"user_tz":-120,"elapsed":589,"user":{"displayName":"רוני ש","userId":"03957075222652512697"}}},"execution_count":6,"outputs":[],"source":["# 6) Define FastAPI app\n","import base64\n","import io\n","import threading\n","from fastapi import FastAPI\n","from pydantic import BaseModel\n","\n","app = FastAPI()\n","_predictor_lock = threading.Lock()\n","\n","class PredictRequest(BaseModel):\n","    image: str  # base64-encoded PNG\n","    box: list   # [x0, y0, x1, y1]\n","\n","@app.get(\"/health\")\n","def health():\n","    import torch\n","    return {\n","        \"torch_available\": True,\n","        \"torch_version\": torch.__version__,\n","        \"cuda_available\": torch.cuda.is_available(),\n","        \"cuda_device_count\": torch.cuda.device_count(),\n","    }\n","\n","@app.post(\"/predict\")\n","def predict(req: PredictRequest):\n","    image_bytes = base64.b64decode(req.image)\n","    image = Image.open(io.BytesIO(image_bytes)).convert(\"RGB\")\n","    image_np = np.array(image)\n","\n","    box = np.array(req.box, dtype=np.float32)\n","    with _predictor_lock:\n","        predictor.set_image(image_np)\n","        masks, _, _ = predictor.predict(box=box, multimask_output=False)\n","\n","    mask = (masks[0] * 255).astype(np.uint8)\n","    mask_img = Image.fromarray(mask)\n","    buffer = io.BytesIO()\n","    mask_img.save(buffer, format=\"PNG\")\n","    mask_b64 = base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n","    return {\n","        \"mask\": mask_b64,\n","        \"mask_metadata\": {\n","            \"shape\": list(mask.shape),\n","            \"dtype\": str(mask.dtype),\n","        },\n","    }\n"],"id":"JRMETcm-_xZZ"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WDh1juVT_xZa","executionInfo":{"status":"ok","timestamp":1769940036853,"user_tz":-120,"elapsed":291,"user":{"displayName":"רוני ש","userId":"03957075222652512697"}},"outputId":"888ea443-f8eb-424e-bdc1-e17b5095efb7"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Server started on port 8000.\n"]}],"source":["# 7) Start FastAPI server in the background\n","import threading\n","import uvicorn\n","\n","def run_server():\n","    uvicorn.run(app, host=\"0.0.0.0\", port=8000, log_level=\"info\")\n","\n","thread = threading.Thread(target=run_server, daemon=True)\n","thread.start()\n","print(\"Server started on port 8000.\")\n"],"id":"WDh1juVT_xZa"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qzIyLpy0_xZa","executionInfo":{"status":"ok","timestamp":1769940042390,"user_tz":-120,"elapsed":5527,"user":{"displayName":"רוני ש","userId":"03957075222652512697"}},"outputId":"5c897915-5a8c-45c5-e15f-c5707ff47f18"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:     Started server process [1348]\n","INFO:     Waiting for application startup.\n","INFO:     Application startup complete.\n","INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"]},{"output_type":"stream","name":"stdout","text":["Public URL: NgrokTunnel: \"https://monogenetic-nonmalarial-nia.ngrok-free.dev\" -> \"http://localhost:8000\"\n"]}],"source":["# 8) Expose server via ngrok\n","import os\n","from pyngrok import ngrok\n","from google.colab import userdata\n","\n","ngrok_token = userdata.get('NGROK')\n","if not ngrok_token:\n","    raise ValueError('NGROK_AUTHTOKEN environment variable is required.')\n","ngrok.set_auth_token(ngrok_token)\n","\n","public_url = ngrok.connect(8000, \"http\")\n","print(\"Public URL:\", public_url)\n"],"id":"qzIyLpy0_xZa"}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.x"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}